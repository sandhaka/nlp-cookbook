{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Training and updating models\n",
    "You can usually make the model more accurate by showing it examples from your domain.\n",
    "You often also want to predict categories specific to your problem, so the model needs to learn about them.\n",
    "This is essential for text classification, very useful for entity recognition and a little less critical for tagging and parsing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Creating Training Data\n",
    "`Matcher` is a great way to quickly create training data for named entity models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone X]\n",
      "[iPhone 8]\n",
      "[iPhone 11, iPhone 8]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "TEXTS = [\n",
    "    'How to preorder the iPhone X',\n",
    "    'iPhone X is coming',\n",
    "    'Should I pay $1,000 for the iPhone X?',\n",
    "    'The iPhone 8 reviews are here',\n",
    "    \"iPhone 11 vs iPhone 8: What's the difference?\",\n",
    "    'I need a new phone! Any tips?'\n",
    "]\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match \"iphone\" and \"x\"\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "# Token whose lowercase form matches \"iphone\" and a digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True}]\n",
    "# Add patterns to the matcher and create docs with matched entities\n",
    "matcher.add(\"GADGET\", [pattern1, pattern2])\n",
    "\n",
    "docs = []\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=match_id) for match_id, start, end in matches]\n",
    "    print(spans)\n",
    "    doc.ents = spans\n",
    "    docs.append(doc)\n",
    "\n",
    "doc_bin = DocBin(docs=docs)\n",
    "# doc_bin.to_disk('./train.spacy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T14:51:49.950720Z",
     "end_time": "2023-04-26T14:52:02.230776Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Configuring Training\n",
    "spaCy uses a config file, usually called config.cfg, as the \"single source of truth\" for all settings. The config file defines how to initialize the nlp object, which pipeline components to add and how their internal model implementations should be configured. It also includes all settings for the training process and how to load the data, including hyperparameters.\n",
    "\n",
    "The quickstart widget in the documentation lets you generate a config interactively by selecting the language and pipeline components you need, as well as optional hardware and optimization settings.\n",
    "\n",
    "To train a pipeline, all you need is the config file and the training and development data.\n",
    "The first argument of spacy train is the path to the config file. The --output argument lets you specify a directory for saving the final trained pipeline.\n",
    "You can also override different config settings on the command line. In this case, we override paths.train using the path to the train.spacy file and paths.dev using the dev.spacy file.\n",
    "\n",
    "`$ python -m spacy train ./config.cfg --output ./output --paths.train train.spacy --paths.dev dev.spacy`\n",
    "\n",
    "- `train`: the command to run\n",
    "- `config.cfg`: the path to the config file\n",
    "- `--output`: the path to the output directory to save the trained pipeline\n",
    "- `--paths.train`: override with path to the training data\n",
    "- `--paths.dev`: override with path to the evaluation data\n",
    "\n",
    "##### Example output\n",
    "\n",
    "```\n",
    "============================ Training pipeline ============================\n",
    "ℹ Pipeline: ['tok2vec', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "\n",
    "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE\n",
    "---  ------  ------------  --------  ------  ------  ------  ------\n",
    "  0       0          0.00     26.50    0.73    0.39    5.43    0.01\n",
    "  0     200         33.58    847.68   10.88   44.44    6.20    0.11\n",
    "  1     400         70.88    267.65   33.50   45.95   26.36    0.33\n",
    "  2     600         67.56    156.63   45.32   62.16   35.66    0.45\n",
    "  3     800        138.28    134.12   48.17   74.19   35.66    0.48\n",
    "  4    1000        177.95    109.77   51.43   66.67   41.86    0.51\n",
    "  6    1200         94.95     52.13   54.63   67.82   45.74    0.55\n",
    "  8    1400        126.85     66.19   56.00   65.62   48.84    0.56\n",
    " 10    1600         38.34     24.16   51.96   70.67   41.09    0.52\n",
    " 13    1800        105.14     23.23   56.88   69.66   48.06    0.57\n",
    "\n",
    "✔ Saved pipeline to output directory\n",
    "/path/to/output/model-last\n",
    "```\n",
    "\n",
    "You can load your trained pipeline by passing the path to spacy.load.\n",
    "\n",
    "```\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"/path/to/output/model-best\")\n",
    "doc = nlp(\"iPhone 11 vs iPhone 8: What's the difference?\")\n",
    "print(doc.ents)\n",
    "```\n",
    "\n",
    "To make it easy to deploy your pipelines, spaCy provides a handy command to package them as Python packages. The spacy package command takes the path to your exported pipeline and an output directory. It then generates a Python package containing your pipeline. The Python package is a .tar.gz file and can be installed into your environment.\n",
    "You can also provide an optional name and version on the command. This lets you manage multiple different versions of a pipeline, for example, if you decide to customize your pipeline later or train it with more data.\n",
    "The package behaves just like any other Python package. After installation, you can load your pipeline using its name. Note that spaCy will automatically add the language code to the name. So your pipeline my_pipeline will become en_my_pipeline.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`python -m spacy package /path/to/output/model-best ./packages --name my_pipeline --version 1.0.0`\n",
    "\n",
    "`cd ./packages/en_my_pipeline-1.0.0`\n",
    "\n",
    "`pip install dist/en_my_pipeline-1.0.0.tar.gz`\n",
    "\n",
    "Load and use the pipeline after installation:\n",
    "\n",
    "`nlp = spacy.load(\"en_my_pipeline\")`"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
