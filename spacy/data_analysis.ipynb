{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:35:09.056783Z",
     "end_time": "2023-04-24T11:35:11.810931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7211811266693931283\n",
      "automobile\n"
     ]
    }
   ],
   "source": [
    "# Hashing\n",
    "import spacy\n",
    "nlp = spacy.blank(\"it\")\n",
    "_ = nlp(\"Lunedì andrò in ufficio in automobile\")\n",
    "word_hash = nlp.vocab.strings[\"automobile\"]\n",
    "print(word_hash)\n",
    "print(nlp.vocab.strings[word_hash])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "# The words and spaces to create the doc from\n",
    "words = [\"Hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "# Create a span manually\n",
    "span = Span(doc, 0, 2)\n",
    "\n",
    "# Create a span with a label\n",
    "span_with_label = Span(doc, 0, 2, label=\"GREETING\")\n",
    "\n",
    "# Add span to the doc.ents\n",
    "doc.ents = [span_with_label]\n",
    "\n",
    "print(doc.text)\n",
    "for ent in doc.ents:\n",
    "    print(ent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:35:11.813912Z",
     "end_time": "2023-04-24T11:35:11.815466Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found proper noun before a verb: Berlin\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Berlin looks like a nice city\")\n",
    "\n",
    "# Get all tokens and part-of-speech tags\n",
    "for token in doc:\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        next_token = doc[token.i + 1]\n",
    "        if next_token.pos_ == \"VERB\":\n",
    "            print(\"Found proper noun before a verb:\", doc[token.i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:35:11.816352Z",
     "end_time": "2023-04-24T11:35:12.119587Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758854418212424\n",
      "0.5835631668074686\n"
     ]
    }
   ],
   "source": [
    "# Similarity\n",
    "\n",
    "# Load a larger pipeline with vectors\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc1 = nlp(\"Milano looks like a nice city\")\n",
    "doc2 = nlp(\"Firenze looks like a nice city\")\n",
    "doc3 = nlp(\"Roma is the larger city\")\n",
    "\n",
    "print(doc1.similarity(doc2))\n",
    "print(doc1.similarity(doc3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:35:12.120142Z",
     "end_time": "2023-04-24T11:35:12.782759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love cats\n",
      "very happy\n",
      "very very happy\n"
     ]
    }
   ],
   "source": [
    "# Recap rule-based matching\n",
    "# Initialize with the shared vocab\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Patterns are lists of dictionaries describing the tokens\n",
    "pattern = [{\"LEMMA\": \"love\", \"POS\": \"VERB\"}, {\"LOWER\": \"cats\"}]\n",
    "matcher.add(\"LOVE_CATS\", [pattern])\n",
    "\n",
    "# Operators can specify how often a token should be matched\n",
    "pattern = [{\"TEXT\": \"very\", \"OP\": \"+\"}, {\"TEXT\": \"happy\"}]\n",
    "matcher.add(\"VERY_HAPPY\", [pattern])\n",
    "\n",
    "# Calling matcher on doc returns list of (match_id, start, end) tuples\n",
    "doc = nlp(\"I love cats and I'm very very happy\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "for m_id, m_start, m_end in matches:\n",
    "    print(doc[m_start:m_end])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:35:12.785198Z",
     "end_time": "2023-04-24T11:35:12.790346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n",
      "cloud\n",
      "company\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\"Amazon has earned a reputation as a disruptor of well-established industries through technological innovation and 'aggressive' reinvestment of profits into capital expenditures. As of 2023, it is the world's largest online retailer and marketplace, smart speaker provider, cloud computing service through AWS, live-streaming service through Twitch, and Internet company as measured by revenue and market share.\")\n",
    "\n",
    "cloud_pattern = [{\"LEMMA\": \"cloud\", \"POS\": \"ADJ\"}]\n",
    "company_pattern = [{\"TEXT\": \"company\"}]\n",
    "scalar_pattern = [{\"IS_DIGIT\": True}]\n",
    "matcher.add(\"CLOUD\",[cloud_pattern])\n",
    "matcher.add(\"COMPANY\", [company_pattern])\n",
    "matcher.add(\"DIGIT\", [scalar_pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for m_id, m_start, m_end in matches:\n",
    "    print(doc[m_start:m_end])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:35:12.791479Z",
     "end_time": "2023-04-24T11:35:13.119262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: Golden Retriever\n"
     ]
    }
   ],
   "source": [
    "# Phrases matching\n",
    "from spacy.matcher import PhraseMatcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "pattern = nlp(\"Golden Retriever\")\n",
    "matcher.add(\"DOG\", [pattern])\n",
    "doc = nlp(\"I have a Golden Retriever\")\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # Get the matched span\n",
    "    span = doc[start:end]\n",
    "    print(\"Matched span:\", span.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:35:52.120289Z",
     "end_time": "2023-04-24T11:35:52.415806Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
